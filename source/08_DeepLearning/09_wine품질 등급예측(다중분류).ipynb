{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4222a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:00:28.837832Z",
     "start_time": "2024-12-19T04:00:25.110989Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # read_csv,get_dumies(원핫인코딩)\n",
    "from sklearn.model_selection import train_test_split #훈련셋과 시험셋 나누기\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Input,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping,Callback\n",
    "from tensorflow.keras import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9134ae7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:00:28.875537Z",
     "start_time": "2024-12-19T04:00:28.871400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142df579",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:01:55.016346Z",
     "start_time": "2024-12-19T03:01:55.009165Z"
    }
   },
   "source": [
    "- Red Wine 품질 등급 예측\n",
    "\n",
    "```\n",
    "1. 데이터 셋 확보 & 전처리\n",
    "    독립변수, 종속변수 분리 -> 독립 변수 스케일 조정(StandardScaler), 종속변수 원핫 인코딩, 훈련셋과 테스트셋 분리\n",
    "2. 모델구성(입력11,출력6)\n",
    "3. 모델 학습 과정 설정(다중분류에 맞는 설정)\n",
    "4. 학습시키기(callbacks이용)\n",
    "5. 모델 평가 - 그래프,평가(테스트셋), 교차표\n",
    "6. 모델 저장 및 모델사용하기\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f87b279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:00:30.907619Z",
     "start_time": "2024-12-19T04:00:30.872341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redwine = pd.read_csv('./data/winequality-red.csv',sep=';')\n",
    "redwine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbae449c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:00:32.261813Z",
     "start_time": "2024-12-19T04:00:32.254834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 4, 8, 3], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redwine.quality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b00bf12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:11:04.805486Z",
     "start_time": "2024-12-19T04:11:04.776342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  \n",
       "0         9.4  \n",
       "1         9.8  \n",
       "2         9.8  \n",
       "3         9.8  \n",
       "4         9.4  \n",
       "...       ...  \n",
       "1594     10.5  \n",
       "1595     11.2  \n",
       "1596     11.0  \n",
       "1597     10.2  \n",
       "1598     11.0  \n",
       "\n",
       "[1599 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       5\n",
       "2       5\n",
       "3       6\n",
       "4       5\n",
       "       ..\n",
       "1594    5\n",
       "1595    6\n",
       "1596    6\n",
       "1597    5\n",
       "1598    6\n",
       "Name: quality, Length: 1599, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Input= redwine.iloc[:,:-1]\n",
    "target= redwine.iloc[:,-1]\n",
    "display(Input)\n",
    "display(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e41387c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:00:35.498098Z",
     "start_time": "2024-12-19T04:00:35.487914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale 조정(StandardScaler)\n",
    "scaler = StandardScaler()\n",
    "scaled_input = pd.DataFrame(scaler.fit_transform(Input))\n",
    "scaled_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73a20a6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:12:53.981023Z",
     "start_time": "2024-12-19T04:12:53.974855Z"
    }
   },
   "outputs": [],
   "source": [
    "# 종속변수 원핫 인코딩(get_dummies)\n",
    "target = get_dummies(target).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52b33e21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:13:23.485966Z",
     "start_time": "2024-12-19T04:13:23.479785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 6)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0603bbbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:01:05.911054Z",
     "start_time": "2024-12-19T04:01:05.904073Z"
    }
   },
   "outputs": [],
   "source": [
    "# 종속변수 원핫 인코딩(get_dummies)\n",
    "# Y_train = get_dummies(y_train)\n",
    "# Y_test = get_dummies(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bafc3367",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:13:30.949832Z",
     "start_time": "2024-12-19T04:13:30.943704Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaled_input와 target => 학습셋: 테스트셋 = 0.75:0.25\n",
    "X_train,X_test,y_train,y_test = train_test_split(scaled_input,\n",
    "                                                target,\n",
    "                                                test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efa5e2ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:10:26.922046Z",
     "start_time": "2024-12-19T04:10:26.854451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 100)               1200      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,601\n",
      "Trainable params: 41,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성 & 모델 구성\n",
    "model=Sequential()\n",
    "model.add(Dense(units=100, input_dim=11,activation = 'relu'))\n",
    "model.add(Dense(units=200, activation = 'relu'))\n",
    "model.add(Dense(units=100, activation = 'relu'))\n",
    "model.add(Dense(units=1, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cec66ca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:10:28.793985Z",
     "start_time": "2024-12-19T04:10:28.782729Z"
    }
   },
   "outputs": [],
   "source": [
    "#model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.compile(loss = 'binary_crossentropy',optimizer='adam', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea2e1b6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T04:10:50.188565Z",
     "start_time": "2024-12-19T04:10:29.527654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "38/38 [==============================] - 1s 2ms/step - loss: -75.3820 - binary_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -1443.2261 - binary_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -10649.7666 - binary_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -45419.4102 - binary_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -139628.9844 - binary_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -345063.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -734440.4375 - binary_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -1396047.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -2437868.2500 - binary_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -3981746.7500 - binary_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -6165602.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -9117532.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -13003535.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -18035186.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -24316744.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -32108452.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -41588900.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -52990968.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -66445552.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -82239928.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -100485560.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -121498240.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -145437760.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -172607904.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -203210608.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 26/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -237357568.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 27/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -275549696.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -317958496.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 29/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -364627168.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 30/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -416172384.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 31/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -472144128.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 32/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -533287136.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 33/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -599819008.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 34/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -671903744.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 35/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -749800896.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 36/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -833679232.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 37/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -924126336.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 38/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -1021537664.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 39/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -1125392384.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 40/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -1236365056.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 41/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -1354071040.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 42/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -1480397952.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 43/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -1613777536.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 44/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -1755122944.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 45/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -1905364736.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 46/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -2063722880.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 47/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -2231953664.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 48/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -2408062464.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 49/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -2594179584.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 50/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -2789792512.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 51/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -2994509312.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 52/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -3209705216.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 53/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -3435506688.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 54/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -3671032320.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 55/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -3916431872.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 56/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -4173050880.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 57/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -4441526784.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 58/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -4719724032.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 59/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -5010786816.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 60/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -5313491968.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 61/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -5628876288.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 62/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -5956224512.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 63/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -6295948288.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 64/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -6646641152.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 65/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -7011696128.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 66/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -7390588416.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 67/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -7782064128.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 68/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -8185521664.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 69/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -8603508736.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 70/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -9037396992.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 71/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -9484750848.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 72/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -9945692160.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 73/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -10421063680.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 74/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -10912624640.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 75/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -11416584192.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 76/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -11938149376.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 77/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -12472826880.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 78/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -13023019008.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 79/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -13590133760.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 80/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -14175782912.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 81/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -14775433216.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 82/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -15392163840.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 83/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -16026396672.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 84/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -16676147200.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 85/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -17342918656.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 86/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -18028920832.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 87/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -18734163968.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 88/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -19456546816.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 89/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -20199075840.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 90/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -20958922752.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 91/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -21732937728.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 92/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -22527500288.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 93/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -23338356736.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 94/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -24172955648.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 95/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -25024139264.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 96/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -25893445632.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 97/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -26789494784.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 98/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -27699070976.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 99/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -28635920384.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 100/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -29585725440.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 101/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -30559358976.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 102/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -31559223296.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 103/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -32577406976.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 104/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -33618921472.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 105/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -34681372672.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 106/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -35761188864.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 107/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -36864446464.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 108/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -37994954752.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 109/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -39144730624.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 110/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -40313753600.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 111/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -41504165888.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 112/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -42719043584.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 113/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -43955425280.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 114/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -45219282944.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 115/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -46503555072.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 116/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -47813226496.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 117/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -49144098816.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 118/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -50501976064.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 119/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -51884220416.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 120/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -53300396032.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 121/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -54728065024.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 122/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -56191102976.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 123/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -57674031104.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 124/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -59176599552.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 125/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -60718059520.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 126/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -62274396160.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 127/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -63868964864.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 128/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -65483816960.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 129/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -67133149184.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 130/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -68811964416.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 131/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -70506995712.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 132/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -72244928512.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 133/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -73992167424.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 134/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -75789344768.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 135/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -77604118528.0000 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -79434014720.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 137/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -81311014912.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 138/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -83190210560.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 139/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -85122105344.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 140/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -87071621120.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 141/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -89052856320.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 142/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -91062083584.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 143/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -93115252736.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 144/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -95177269248.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 145/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -97292533760.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 146/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -99430244352.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 147/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -101601304576.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 148/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -103789150208.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 149/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -106022764544.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 150/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -108276211712.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 151/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -110567391232.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 152/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -112893927424.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 153/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -115249012736.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 154/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -117638340608.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 155/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -120065204224.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 156/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -122520666112.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 157/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -125012623360.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 158/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -127536168960.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 159/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -130086404096.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 160/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -132683907072.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 161/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -135308443648.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 162/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -137981362176.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 163/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -140668862464.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 164/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -143409659904.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 165/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -146172870656.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 166/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -148976074752.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 167/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -151813898240.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 168/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -154693517312.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 169/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -157603823616.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 170/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -160562561024.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 171/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -163544121344.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 172/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -166584942592.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 173/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -169656877056.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 174/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -172768280576.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 175/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -175912484864.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 176/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -179100090368.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 177/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -182325493760.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 178/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -185590743040.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 179/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -188892856320.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 180/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -192231473152.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 181/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -195605807104.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 182/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -199036764160.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 183/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -202473832448.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 184/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -205974306816.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 185/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -209504731136.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 186/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -213104328704.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 187/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -216704909312.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 188/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -220378300416.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 189/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -224073957376.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 190/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -227824812032.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 191/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -231589478400.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 192/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -235434491904.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 193/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -239306735616.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 194/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -243216941056.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 195/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -247181836288.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 196/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -251187101696.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 197/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -255249039360.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 198/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -259339403264.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 199/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -263497973760.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 200/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -267705155584.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 201/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -271920775168.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 202/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -276201046016.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 203/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -280528486400.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 204/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -284893511680.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 205/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -289300185088.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 206/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -293767020544.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 207/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -298271342592.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 208/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -302831665152.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 209/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -307431538688.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 210/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -312072699904.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 211/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -316783886336.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 212/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -321539538944.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 213/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -326325633024.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 214/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -331175985152.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 215/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -336073687040.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 216/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -341008744448.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 217/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -345983975424.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 218/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -351030575104.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 219/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -356112465920.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 220/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -361241739264.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 221/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -366436777984.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 222/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -371672940544.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 223/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -376984010752.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 224/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -382353375232.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 225/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -387753181184.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 226/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -393226027008.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 227/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -398730330112.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 228/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -404311015424.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 229/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -409928368128.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 230/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -415575867392.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 231/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -421310169088.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 232/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -427101028352.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 233/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -432918790144.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 234/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -438811918336.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 235/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -444765732864.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 236/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -450780430336.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 237/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -456805908480.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 238/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -462926020608.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 239/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -469080113152.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 240/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -475297218560.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 241/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -481560625152.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 242/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -487886487552.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 243/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -494267596800.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 244/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -500718698496.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 245/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -507193917440.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 246/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -513785004032.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 247/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -520388837376.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 248/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -527087304704.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 249/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -533847048192.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 250/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -540652863488.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 251/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -547548495872.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 252/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -554502258688.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 253/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -561466834944.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 254/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -568551735296.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 255/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -575607013376.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 256/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -582754959360.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 257/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -590024605696.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 258/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -597319942144.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 259/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -604669607936.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 260/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -612130488320.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 261/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -619608670208.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 262/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: -627150094336.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 263/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: -634765312000.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 264/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -642430795776.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 265/300\n",
      "38/38 [==============================] - 0s 1ms/step - loss: -650142744576.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 266/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -657942708224.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 267/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -665777405952.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 268/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 2ms/step - loss: -673729347584.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 269/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -681753378816.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 270/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -689829773312.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 271/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -697939984384.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 272/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -706166128640.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 273/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -714425171968.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 274/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -722749882368.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 275/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -731159920640.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 276/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -739644080128.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 277/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -748171231232.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 278/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -756757823488.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 279/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -765440425984.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 280/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -774147080192.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 281/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -782975631360.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 282/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -791823056896.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 283/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -800770490368.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 284/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -809785753600.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 285/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -818890211328.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 286/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -828065710080.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 287/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -837301305344.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 288/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -846598438912.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 289/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -855992893440.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 290/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -865461338112.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 291/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -874993090560.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 292/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -884613906432.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 293/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -894278893568.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 294/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -904042119168.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 295/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -913875468288.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 296/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -923742175232.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 297/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -933792841728.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 298/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -943824240640.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 299/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -953925042176.0000 - binary_accuracy: 0.0000e+00\n",
      "Epoch 300/300\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -964098129920.0000 - binary_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "               epochs=300,\n",
    "               # batch_size=350,\n",
    "               # validation_split=0.2 # 검증데이터 비율(훈련데이터셋 중 20%를 검증용 데이터로)\n",
    "               \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a50a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb483c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번\n",
    "((X_train,Y_train),(X_test,Y_test))=mnist.load_data()\n",
    "\n",
    "#훈련셋(6만)= 5만개 +만개(val)\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "# 독립변수 전처리 :(5000,28,28) ->(50000,784)-> 실수형변환 -> 스케일조정(255.00으로나눠)\n",
    "X_train=X_train.reshape(-1,784).astype('float32')/255.0\n",
    "X_val = X_val.reshape(-1,784).astype('float32')/255.0\n",
    "X_test = X_test.reshape(-1,784).astype('float32')/255.0\n",
    "X_train.shape,X_val.shape,X_test.shape\n",
    "\n",
    "# 훈련셋(5만)과 검증셋(만)-> 700개,300개만 random으로 choice\n",
    "train_idxs=np.random.choice(50000,700)\n",
    "val_idxs=np.random.choice(10000,300)\n",
    "\n",
    "X_train= X_train[train_idxs]\n",
    "Y_train= Y_train[train_idxs]\n",
    "X_val = X_val[val_idxs]\n",
    "Y_val = Y_val[val_idxs]\n",
    "\n",
    "# 종속변수 전처리: 원핫 인코딩(to_categorical(넘파이배열)pd.get_dummies(데이터프레임을 반환))\n",
    "print('원핫인코딩 전 shape:',Y_train.shape,Y_val.shape,Y_test.shape)\n",
    "#원핫인코딩\n",
    "Y_train = to_categorical(Y_train,10)\n",
    "Y_val = to_categorical(Y_val)\n",
    "Y_test = to_categorical(Y_test)\n",
    "print('원핫인코딩 전 shape:',Y_train.shape,Y_val.shape,Y_test.shape)\n",
    "\n",
    "# 모델구성하기\n",
    "model= Sequential()\n",
    "model.add(Input(shape=(784,)))\n",
    "model.add(Dense(units=2,activation='relu'))\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "model.summary()\n",
    "# 모델 학습과정 설정\n",
    "model.compile(loss='categorical_crossentropy',optimizer = 'sgd',metrics=['accuracy'])\n",
    "# 모델 학습(콜백 적용)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlyStopping = EarlyStopping(patience=20) # val_accuracy가 연달아 2번이상 성능이 좋아지지않으면 stop(loss,accuracy,val_loss,val_accuracy)\n",
    "hist = model.fit(X_train, Y_train , epochs=2000,batch_size=100,\n",
    "                validation_data=(X_val,Y_val),\n",
    "                callbacks=[earlyStopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73bae21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c53aa73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd7fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "246.25px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
